{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141344d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c96d366",
   "metadata": {},
   "source": [
    "# Cargando las librerias que utilizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import mlflow\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up MLFlow\n",
    "mlflow.set_experiment('Transfer-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f3824",
   "metadata": {},
   "source": [
    "# Analizando nuestros datos (despues de aplicar Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path principal a nuestros datos\n",
    "data_path = \"C:/Users/abrah/Documents/Repos/RPatrones/ClasificaImagenes/data/Limpieza02/Final\"\n",
    "OK_images_path = os.listdir(data_path + '/OK/')\n",
    "NG_images_path = os.listdir(data_path + '/NG/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos una muestra de las imagenes OK\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    img = image.load_img(data_path + '/OK/' + OK_images_path[i])\n",
    "    print(image.img_to_array(img).shape)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"OK Image\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos una muestra de las imagenes NG\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    img = image.load_img(data_path + '/NG/' + NG_images_path[i])\n",
    "    print(image.img_to_array(img).shape)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"NG Image\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1e8cf",
   "metadata": {},
   "source": [
    "# Separamos nuestros datos en entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos nuestros datos en conjuntos de entrenamiento, validación y test.\n",
    "output_folder = 'C:/Users/abrah/Documents/Repos/RPatrones/ClasificaImagenes/data/Limpieza02/splitted/'\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "splitfolders.ratio(data_path,output=output_folder, seed=1237,\n",
    "            ratio = (train_ratio,val_ratio,test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82abe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/abrah/Documents/Repos/RPatrones/ClasificaImagenes/data/Limpieza01/splitted/'\n",
    "# Paths de los datos de entrenamiento\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_ok_dir = os.path.join(train_dir, 'ok')\n",
    "train_ng_dir = os.path.join(train_dir, 'ng')\n",
    "\n",
    "#  Paths de los datos de validación\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "val_ok_dir = os.path.join(val_dir, 'ok')\n",
    "val_ng_dir = os.path.join(val_dir, 'ng')\n",
    "\n",
    "# Paths de los datos de prueba\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_ok_dir = os.path.join(test_dir, 'ok')\n",
    "test_ng_dir = os.path.join(test_dir, 'ng')\n",
    "\n",
    "# Número de datos utilizados para entrenamiento\n",
    "# Lo utilizaremos para especificar el parametro step_size del modelo.\n",
    "num_total_train = len(os.listdir(train_ok_dir)) + len(os.listdir(train_ng_dir))\n",
    "num_total_val = len(os.listdir(val_ok_dir)) + len(os.listdir(val_ng_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de datos de entrenamiento\n",
    "print(f'Training OK images: {len(os.listdir(train_ok_dir))}')\n",
    "print(f'Training NG images: {len(os.listdir(train_ng_dir))}')\n",
    "\n",
    "# Número de datos de validación\n",
    "print(f'Validation OK images: {len(os.listdir(val_ok_dir))}')\n",
    "print(f'Validation NG images: {len(os.listdir(val_ng_dir))}')\n",
    "\n",
    "# Número de datos de prueba\n",
    "print(f'Test OK images: {len(os.listdir(test_ok_dir))}')\n",
    "print(f'Test NG images: {len(os.listdir(test_ng_dir))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbcaa1",
   "metadata": {},
   "source": [
    "# Formateamos nuestro data-set para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db959ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = 256     # Images of 256 x 256\n",
    "num_channels = 3    # Las imagenes estan en escala de grises.\n",
    "batch_size = 8      # Como cargaremos los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos de entrenamiento y los cargamos en batches.\n",
    "normalize_img_train = image.ImageDataGenerator(rescale=1.0/255)\n",
    "norm_train_data = normalize_img_train.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=train_dir,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "    #color_mode='grayscale',\n",
    "    class_mode='binary'\n",
    ")\n",
    "# Normalizamos los datos de validación y los cargamos en batches.\n",
    "normalize_img_val = image.ImageDataGenerator(rescale=1.0/255)\n",
    "norm_val_data = normalize_img_val.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=val_dir,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "    #color_mode='grayscale',\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Normalizamos los datos de prueba y los cargamos en batches.\n",
    "normalize_img_test = image.ImageDataGenerator(rescale=1.0/255)\n",
    "norm_test_data = normalize_img_test.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=test_dir,\n",
    "    # shuffle=True,\n",
    "    target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "    #color_mode='grayscale',\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929792be",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5c051",
   "metadata": {},
   "source": [
    "# Creando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.keras.autolog() # Utilizando MLflow para guardar los parametros utilziados y metricas obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778efbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = tf.keras.applications.VGG19(input_shape=(IMG_SHAPE, IMG_SHAPE, num_channels), \n",
    "                                                include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ec553",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(200, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b482da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(pre_trained_model.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab255522",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2330d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/Users/abrah/Documents/Repos/RPatrones/ClasificaImagenes/notebooks/models/brake_vgg_2.h5'\n",
    "# Se queda con el mejor modelo\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1,save_best_only=True,mode='min')\n",
    "# Si no hay mejora en la perdida de los datos de validación, paramos.\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=3)\n",
    "\n",
    "callbacks = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96694a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e15f10",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4dd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "epochs = 5\n",
    "\n",
    "start_time = time.time()\n",
    "classifier = model.fit(\n",
    "    norm_train_data,\n",
    "    steps_per_epoch=(num_total_train//batch_size),\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    validation_data=norm_val_data,\n",
    "    validation_steps=(num_total_val//batch_size),\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "total_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7663640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/abrah/Documents/Repos/RPatrones/ClasificaImagenes/notebooks/models/brake_vgg_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training accuracy and loss\n",
    "# Training and validation accuracy:\n",
    "print(classifier.history['val_loss'])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(classifier.history['acc'])\n",
    "plt.plot(classifier.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.figure(figsize = (60,20))\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(classifier.history['loss'],)\n",
    "plt.plot(classifier.history['val_loss'],)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30990203",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b17898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(norm_test_data,batch_size=batch_size)\n",
    "print('test_loss, test_accuracy', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071563c",
   "metadata": {},
   "source": [
    "# Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff95b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "threshold = 0.50\n",
    "# Predecimos en el conjunto de prueba\n",
    "Y_pred_proba = model.predict(norm_test_data,num_total_train//batch_size)\n",
    "# Asignamos a que clase pertenece.\n",
    "Y_pred_labels = np.where(Y_pred_proba > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5eca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "conf_matrix = confusion_matrix(norm_test_data.classes,Y_pred_labels)\n",
    "print('Confussion Matrix')\n",
    "print(conf_matrix)\n",
    "target_names = ['Bad', 'Good']\n",
    "print(classification_report(norm_test_data.classes, Y_pred_labels,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97cf1d4",
   "metadata": {},
   "source": [
    "# NG IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b84642",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "folder_path = test_ng_dir\n",
    "images_list = os.listdir(folder_path)\n",
    "for img in images_list:\n",
    "    img_path = os.path.join(folder_path, img)\n",
    "    img = plt.imread(img_path)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bed044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "color = 'none'\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "\n",
    "to_show = 8\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "ng_items = np.count_nonzero(norm_test_data.classes == 0)\n",
    "ng_ypred = np.copy(Y_pred_proba[0:ng_items])\n",
    "\n",
    "i = 0\n",
    "for row in range(nrows):\n",
    "    row += 1\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for col in range(ncols):\n",
    "        col += 1\n",
    "        # print(Y_pred_labels[i])\n",
    "        pred = f\"{ng_ypred[i, 0]:.4f}\"\n",
    "        \n",
    "        plt.subplot(1, ncols, col)\n",
    "        plt.text(IMG_SHAPE/2, IMG_SHAPE-5,\"Pred =\" + pred, color=\"orange\", fontdict={\"fontsize\":13,\"fontweight\":'bold',\"ha\":\"center\", \"va\":\"baseline\"})\n",
    "        \n",
    "        if ng_ypred[i] <= threshold:\n",
    "            color = 'g'\n",
    "            true_negative = true_negative +1\n",
    "        else:\n",
    "            color = 'r'\n",
    "            false_positive = false_positive +1\n",
    "        plt.gca().add_patch(Rectangle((0,0),IMG_SHAPE,IMG_SHAPE,linewidth=5,edgecolor=color,facecolor='none'))\n",
    "\n",
    "        plt.imshow(images[i])\n",
    "        i += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('True negative =' +' '+ str(true_negative))\n",
    "print('False negative =' + ' '+ str(false_positive))\n",
    "print ('Total evaluated parts =' + ' ' + str(true_negative+false_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7cdef",
   "metadata": {},
   "source": [
    "# OK Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "folder_path = test_ok_dir\n",
    "images_list = os.listdir(folder_path)\n",
    "for img in images_list:\n",
    "    img_path = os.path.join(folder_path, img)\n",
    "    img = plt.imread(img_path)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f82ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'none'\n",
    "true_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "ok_items = np.count_nonzero(norm_test_data.classes)\n",
    "ok_ypred = np.copy(Y_pred_proba[ng_items:])\n",
    "\n",
    "print ('Evaluation on Good Parts')\n",
    "\n",
    "i = 0\n",
    "for row in range(nrows):\n",
    "    row += 1\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for col in range(ncols):\n",
    "        col += 1\n",
    "        pred = f\"{ok_ypred[i, 0]:.4f}\"\n",
    "        \n",
    "        plt.subplot(1, ncols, col)\n",
    "        plt.text(IMG_SHAPE/2, IMG_SHAPE-5,\"Pred =\" + pred, color=\"orange\", fontdict={\"fontsize\":13,\"fontweight\":'bold',\"ha\":\"center\", \"va\":\"baseline\"})\n",
    "        \n",
    "        if ok_ypred[i] >= threshold:\n",
    "            color = 'g'\n",
    "            true_positive = true_positive +1\n",
    "        else:\n",
    "            color = 'r'\n",
    "            false_negative = false_negative +1\n",
    "        plt.gca().add_patch(Rectangle((0,0),IMG_SHAPE,IMG_SHAPE,linewidth=5,edgecolor=color,facecolor='none'))\n",
    "\n",
    "        plt.imshow(images[i])\n",
    "        i += 1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "print('True positive =' +' '+ str(true_positive))\n",
    "print('False negative =' + ' '+ str(false_negative))\n",
    "print ('Total evaluated parts =' + ' ' + str(true_positive+false_positive))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb6e9f8732d952f850bd4070f64980e6f6165b20af0799e5c2c38efe8635471e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('patrones-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
